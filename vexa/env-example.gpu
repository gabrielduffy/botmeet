# ============================================================================
# Vexa Configuration - GPU Mode
# ============================================================================
# This configuration uses whisperlive-remote with transcription-service
# running in GPU mode. Recommended for production use.
# ============================================================================

# ----------------------------------------------------------------------------
# Authentication & Security
# ----------------------------------------------------------------------------
ADMIN_API_TOKEN=token
# Change this to a secure token in production!

# ----------------------------------------------------------------------------
# WhisperLive Configuration
# ----------------------------------------------------------------------------
# DEVICE_TYPE=remote means whisperlive-remote will use transcription-service
DEVICE_TYPE=remote
# Note: WHISPER_MODEL_SIZE is not used in remote mode - model is configured in transcription-service

LANGUAGE_DETECTION_SEGMENTS=10
# Number of segments to analyze before detecting language

VAD_FILTER_THRESHOLD=0.5
# Voice Activity Detection threshold (0.0-1.0)
# Lower = more permissive (catches more speech, may include noise)
# Higher = more strict (fewer false positives, may miss quiet speech)

# Note: WL_MAX_CLIENTS is automatically set to 1000 for remote mode (hardcoded in WhisperLive)
# No need to configure it - remote mode always uses high capacity
# These are included for docker-compose compatibility (not used in remote mode):
WHISPER_MODEL_SIZE=
WL_MAX_CLIENTS=

# ----------------------------------------------------------------------------
# Remote Transcription Service Configuration
# ----------------------------------------------------------------------------
# Transcription service runs in GPU mode (docker-compose.yml)
REMOTE_TRANSCRIBER_URL=http://transcription-service:80/v1/audio/transcriptions
# API endpoint for transcription-service (GPU mode load balancer)

REMOTE_TRANSCRIBER_API_KEY=
# API key for transcription-service authentication
# Should match API_TOKEN in services/transcription-service/.env
# If empty, service will accept all requests (not recommended for production)


# ----------------------------------------------------------------------------
# Bot Configuration
# ----------------------------------------------------------------------------
BOT_IMAGE_NAME=vexa-bot:dev
# Docker image name for vexa-bot containers

# ----------------------------------------------------------------------------
# Exposed Host Ports
# ----------------------------------------------------------------------------
# Ports exposed on the host machine
API_GATEWAY_HOST_PORT=8056
ADMIN_API_HOST_PORT=8057
TRANSCRIPTION_COLLECTOR_HOST_PORT=8123
POSTGRES_HOST_PORT=5438
# Transcription Service (GPU mode) runs on port 8083 by default

# ----------------------------------------------------------------------------
# Database Configuration
# ----------------------------------------------------------------------------
# Set REMOTE_DB=true to use external PostgreSQL instead of local Docker postgres
REMOTE_DB=false

# Remote Database Credentials (only used when REMOTE_DB=true)
# Uncomment and configure if using remote database:
# DB_HOST=your-remote-db-host
# DB_PORT=5432
# DB_NAME=your-db-name
# DB_USER=your-db-user
# DB_PASSWORD=your-db-password
# DB_SSL_MODE=require

# ----------------------------------------------------------------------------
# Optional: Base URLs (for documentation/reference)
# ----------------------------------------------------------------------------
# BASE_URL=http://localhost:8056
# WS_URL=ws://localhost:8056/ws
