# Model configuration
MODEL_SIZE=large-v3-turbo

# Available models (all multilingual):
# - tiny, base, small, medium, large-v2, large-v3, large-v3-turbo
# 
# Recommended: large-v3-turbo + INT8
# - GPU VRAM: ~2.1 GB (validated)
# - Quality: Excellent (95-98% accuracy)
# - Speed: Very fast (>10x real-time)
# - Multilingual: 99+ languages

# Device configuration
# DEVICE=cuda  # For GPU (default)
# DEVICE=cpu   # For CPU-only

# Compute type (optimization)
# COMPUTE_TYPE=int8     # Default: 50-60% VRAM reduction, 2-4x CPU speedup, minimal accuracy loss
# COMPUTE_TYPE=float16  # GPU only: Maximum speed, higher VRAM usage (~6-8 GB)

# CPU optimization (only used when DEVICE=cpu)
# CPU_THREADS=4  # Set to number of physical CPU cores (0 = auto-detect)

# Load management / backpressure
# These control how the service behaves under load.
# Recommended for WhisperLive streaming: FAIL_FAST_WHEN_BUSY=true
MAX_CONCURRENT_TRANSCRIPTIONS=2   # Max concurrent model calls per worker
MAX_QUEUE_SIZE=10                # Max requests waiting (ignored when FAIL_FAST_WHEN_BUSY=true)
FAIL_FAST_WHEN_BUSY=true         # Return 503 immediately when busy (lets WhisperLive keep buffering/coalescing)
BUSY_RETRY_AFTER_S=1             # Retry-After header value (seconds) for busy/overload responses

# Quality parameters (derived from WhisperLive best practices)
# These parameters improve transcription quality and accuracy
BEAM_SIZE=5                    # Beam size: 1 = greedy (fast), 5 = beam search (better quality, slower)
BEST_OF=5                      # Number of candidates when sampling with non-zero temperature
COMPRESSION_RATIO_THRESHOLD=1.8  # If gzip compression ratio > this, treat as failed (hallucination detection) - lowered to catch repetitions
LOG_PROB_THRESHOLD=-1.0        # If avg log probability < this, treat as failed
NO_SPEECH_THRESHOLD=0.6         # If no_speech_prob > this AND log_prob < threshold, consider silent
CONDITION_ON_PREVIOUS_TEXT=false # Use previous output as prompt for next window - DISABLED to prevent repetition loops
PROMPT_RESET_ON_TEMPERATURE=0.3 # Reset prompt if temperature > this (prevents stuck loops) - lowered for more aggressive reset

# VAD (Voice Activity Detection) parameters
VAD_FILTER=true                # Enable VAD to filter out non-speech audio
VAD_FILTER_THRESHOLD=0.5       # VAD onset threshold (0-1): higher = less sensitive to noise
VAD_MIN_SILENCE_DURATION_MS=160  # Minimum silence duration in milliseconds

# Temperature fallback chain (for quality improvement)
# Uses multiple temperatures and falls back if compression_ratio or log_prob thresholds are exceeded
USE_TEMPERATURE_FALLBACK=true  # Enable temperature fallback chain [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]

# API Token for securing the service
# This token must match TRANSCRIPTION_SERVICE_API_TOKEN in the gateway
# If not set, service will accept all requests (not recommended for production)

API_TOKEN=your_secure_token_here




